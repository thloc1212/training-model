{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "845e762d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import torchaudio\n",
    "import torchaudio.functional as taF\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "CONFIG = {\n",
    "    'min_duration': 0.5,\n",
    "    'max_duration': 15.0,\n",
    "    'target_sr': 16000,\n",
    "    'random_seed': 42,\n",
    "}\n",
    "\n",
    "EMOTION_CLASSES = ['neutral', 'happy', 'sad', 'angry']\n",
    "\n",
    "# Dataset paths\n",
    "D1_VISC_PATH = \"ViSEC\"  # sau khi download từ HuggingFace\n",
    "D2_PATH = \"d2\"\n",
    "D3_PATH = \"d3\"\n",
    "\n",
    "# Output paths\n",
    "OUTPUT_DIR = \"data\"\n",
    "TRAIN_PHASE1 = f\"{OUTPUT_DIR}/train/phase1\"\n",
    "TRAIN_PHASE2 = f\"{OUTPUT_DIR}/train/phase2\"\n",
    "VAL_DIR = f\"{OUTPUT_DIR}/val\"\n",
    "TEST_DIR = f\"{OUTPUT_DIR}/test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c923e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 1: LOAD D1 (ViSEC Dataset)\n",
      "============================================================\n",
      "Loaded D1 shape: (5280, 7)\n",
      "Columns: ['speaker_id', 'path', 'duration', 'accent', 'emotion', 'emotion_id', 'gender']\n",
      "   speaker_id                                               path  duration  \\\n",
      "0           0  {'bytes': b'RIFF\\xa69\\x01\\x00WAVEfmt \\x10\\x00\\...  2.508062   \n",
      "1           1  {'bytes': b'RIFFF\\xc8\\x00\\x00WAVEfmt \\x10\\x00\\...  1.600000   \n",
      "2           2  {'bytes': b'RIFFF\\xb8\\x00\\x00WAVEfmt \\x10\\x00\\...  1.472000   \n",
      "3           3  {'bytes': b'RIFFF\\xc8\\x01\\x00WAVEfmt \\x10\\x00\\...  3.648000   \n",
      "4           4  {'bytes': b'RIFFF\\xc0\\x01\\x00WAVEfmt \\x10\\x00\\...  3.584000   \n",
      "\n",
      "  accent  emotion  emotion_id  gender  \n",
      "0  south    happy           0  female  \n",
      "1  south  neutral           1    male  \n",
      "2  south    angry           3  female  \n",
      "3  north    happy           0  female  \n",
      "4  south  neutral           1    male  \n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"STEP 1: LOAD D1 (ViSEC Dataset)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "local_path = hf_hub_download(\n",
    "    repo_id=\"hustep-lab/ViSEC\",\n",
    "    repo_type=\"dataset\",\n",
    "    filename=\"data/train-00000-of-00001.parquet\",\n",
    "    local_dir=\"ViSEC\"\n",
    ")\n",
    "\n",
    "df_d1 = pd.read_parquet(local_path)\n",
    "print(f\"Loaded D1 shape: {df_d1.shape}\")\n",
    "print(f\"Columns: {df_d1.columns.tolist()}\")\n",
    "print(df_d1.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3082eedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 2: PROCESS D1 - Decode & Validate Audio\n",
      "============================================================\n",
      "Decoding D1 audio files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5280/5280 [00:11<00:00, 470.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D1 after decode: 5280 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 2: PROCESS D1 - Decode & Validate Audio\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create temp directory for D1 audio\n",
    "d1_audio_dir = \"temp_d1_audio\"\n",
    "os.makedirs(d1_audio_dir, exist_ok=True)\n",
    "\n",
    "def decode_d1_audio(row, idx):\n",
    "    \"\"\"Decode D1 audio from bytes\"\"\"\n",
    "    try:\n",
    "        raw = row[\"path\"][\"bytes\"]\n",
    "        audio, sr = sf.read(io.BytesIO(raw))\n",
    "        audio = audio.astype(np.float32)\n",
    "        \n",
    "        # Resample if needed\n",
    "        if sr != 16000:\n",
    "            audio_tensor = torchaudio.transforms.Resample(sr, 16000)(\n",
    "                torch.from_numpy(audio).unsqueeze(0)\n",
    "            )\n",
    "            audio = audio_tensor.squeeze(0).numpy()\n",
    "            sr = 16000\n",
    "        \n",
    "        # Calculate duration\n",
    "        duration = len(audio) / sr\n",
    "        \n",
    "        # Save WAV\n",
    "        filepath = os.path.join(d1_audio_dir, f\"d1_{idx}.wav\")\n",
    "        sf.write(filepath, audio, sr)\n",
    "        \n",
    "        return filepath, duration, True\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing D1 sample {idx}: {e}\")\n",
    "        return None, None, False\n",
    "\n",
    "print(\"Decoding D1 audio files...\")\n",
    "results = []\n",
    "for idx in tqdm(range(len(df_d1))):\n",
    "    filepath, duration, success = decode_d1_audio(df_d1.iloc[idx], idx)\n",
    "    results.append({\n",
    "        'audio_path': filepath,\n",
    "        'duration': duration,\n",
    "        'success': success\n",
    "    })\n",
    "\n",
    "df_d1['audio_path'] = [r['audio_path'] for r in results]\n",
    "df_d1['duration'] = [r['duration'] for r in results]\n",
    "df_d1['success'] = [r['success'] for r in results]\n",
    "\n",
    "df_d1 = df_d1[df_d1['success'] == True].reset_index(drop=True)\n",
    "\n",
    "print(f\"D1 after decode: {len(df_d1)} files\")\n",
    "\n",
    "# Map emotion_id to emotion_name\n",
    "emotion_map = {0: 'neutral', 1: 'happy', 2: 'sad', 3: 'angry'}\n",
    "df_d1['emotion'] = df_d1['emotion_id'].map(emotion_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d1d1b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 3: FILTER VALID AUDIO (0.5–15s)\n",
      "============================================================\n",
      "D1 -> Remaining 5277 files (from 5280)\n",
      "Duration range: 1.00s - 13.50s\n",
      "Emotion distribution:\n",
      "emotion\n",
      "happy      1506\n",
      "angry      1466\n",
      "neutral    1226\n",
      "sad        1079\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 3: FILTER VALID AUDIO (0.5–15s)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "MIN_DUR = CONFIG['min_duration']\n",
    "MAX_DUR = CONFIG['max_duration']\n",
    "\n",
    "df_d1_valid = df_d1[\n",
    "    (df_d1['duration'] >= MIN_DUR) & \n",
    "    (df_d1['duration'] <= MAX_DUR)\n",
    "].reset_index(drop=True)\n",
    "\n",
    "print(f\"D1 -> Remaining {len(df_d1_valid)} files (from {len(df_d1)})\")\n",
    "print(f\"Duration range: {df_d1_valid['duration'].min():.2f}s - {df_d1_valid['duration'].max():.2f}s\")\n",
    "print(f\"Emotion distribution:\\n{df_d1_valid['emotion'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27b92b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "beca7e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading D2...\n",
      "D2 loaded: 56\n",
      "\n",
      "Loading D3...\n",
      "D3 loaded: 177\n"
     ]
    }
   ],
   "source": [
    "def load_folder_dataset(dataset_path, dataset_name, out_dir):\n",
    "    \"\"\"\n",
    "    Load dataset from folder/emotion/*.wav\n",
    "    -> decode, resample, save WAV chuẩn 16kHz\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    for emotion in EMOTION_CLASSES:\n",
    "        emotion_dir = os.path.join(dataset_path, emotion)\n",
    "        if not os.path.isdir(emotion_dir):\n",
    "            continue\n",
    "\n",
    "        emotion_out_dir = os.path.join(out_dir, emotion)\n",
    "        os.makedirs(emotion_out_dir, exist_ok=True)\n",
    "\n",
    "        for filename in os.listdir(emotion_dir):\n",
    "            if not filename.lower().endswith(\".wav\"):\n",
    "                continue\n",
    "\n",
    "            in_path = os.path.join(emotion_dir, filename)\n",
    "\n",
    "            try:\n",
    "                # 1) Load bằng soundfile (KHÔNG torchcodec)\n",
    "                audio, sr = sf.read(in_path, dtype=\"float32\")\n",
    "\n",
    "                # 2) Mono\n",
    "                if audio.ndim > 1:\n",
    "                    audio = audio.mean(axis=1)\n",
    "\n",
    "                # 3) Resample\n",
    "                if sr != 16000:\n",
    "                    audio = taF.resample(\n",
    "                        torch.from_numpy(audio), sr, 16000\n",
    "                    ).numpy()\n",
    "                    sr = 16000\n",
    "\n",
    "                # 4) Duration\n",
    "                duration = len(audio) / sr\n",
    "\n",
    "                # 5) Save WAV chuẩn\n",
    "                out_path = os.path.join(\n",
    "                    emotion_out_dir,\n",
    "                    f\"{dataset_name}_{filename}\"\n",
    "                )\n",
    "                sf.write(out_path, audio, sr)\n",
    "\n",
    "                data.append({\n",
    "                    \"audio_path\": out_path,\n",
    "                    \"emotion\": emotion,\n",
    "                    \"duration\": duration,\n",
    "                    \"dataset\": dataset_name,\n",
    "                    \"success\": True\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {in_path}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "print(\"\\nLoading D2...\")\n",
    "df_d2 = load_folder_dataset(D2_PATH, \"D2\", \"temp_d2_audio\")\n",
    "print(f\"D2 loaded: {len(df_d2)}\")\n",
    "\n",
    "print(\"\\nLoading D3...\")\n",
    "df_d3 = load_folder_dataset(D3_PATH, \"D3\", \"temp_d3_audio\")\n",
    "print(f\"D3 loaded: {len(df_d3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b5333cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 5: FILTER D2 & D3 BY DURATION\n",
      "============================================================\n",
      "D2 -> Remaining 56 files (from 56)\n",
      "D3 -> Remaining 175 files (from 177)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 5: FILTER D2 & D3 BY DURATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df_d2_valid = df_d2[\n",
    "    (df_d2['duration'] >= MIN_DUR) & \n",
    "    (df_d2['duration'] <= MAX_DUR)\n",
    "].reset_index(drop=True)\n",
    "\n",
    "df_d3_valid = df_d3[\n",
    "    (df_d3['duration'] >= MIN_DUR) & \n",
    "    (df_d3['duration'] <= MAX_DUR)\n",
    "].reset_index(drop=True)\n",
    "\n",
    "print(f\"D2 -> Remaining {len(df_d2_valid)} files (from {len(df_d2)})\")\n",
    "print(f\"D3 -> Remaining {len(df_d3_valid)} files (from {len(df_d3)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6871de4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 6: CREATE DATA SPLITS\n",
      "============================================================\n",
      "\n",
      "SPLIT SUMMARY:\n",
      "Phase1 (D1 only):     3694 files\n",
      "Phase2 (D1+D2+D3):    3772 files\n",
      "Val (D1 only):        792 files\n",
      "Test (D1+D2+D3):      944 files\n",
      "Total:                9202 files\n",
      "\n",
      "Test distribution:\n",
      "emotion\n",
      "happy      266\n",
      "angry      262\n",
      "neutral    220\n",
      "sad        196\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "STEP 7: RESAMPLE & VALIDATE ALL AUDIO TO 16kHz\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 6: CREATE DATA SPLITS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# D1: Split into val (15%), temp (85%)\n",
    "df_d1_train, df_d1_val = train_test_split(\n",
    "    df_d1_valid,\n",
    "    test_size=0.15,\n",
    "    random_state=CONFIG['random_seed'],\n",
    "    stratify=df_d1_valid['emotion']\n",
    ")\n",
    "\n",
    "# Combine D1_train + D2 + D3 for further split\n",
    "df_combined_rest = pd.concat([df_d1_train, df_d2_valid, df_d3_valid], \n",
    "                              ignore_index=True)\n",
    "\n",
    "# From combined, extract 20% for test (stratified)\n",
    "df_combined_train, df_test = train_test_split(\n",
    "    df_combined_rest,\n",
    "    test_size=0.20,\n",
    "    random_state=CONFIG['random_seed'],\n",
    "    stratify=df_combined_rest['emotion']\n",
    ")\n",
    "\n",
    "# D1 remaining goes to phase1, rest (D2+D3) goes to phase2\n",
    "df_phase1 = df_d1_train[~df_d1_train.index.isin(df_test.index)].copy()\n",
    "df_phase2 = df_combined_train.copy()\n",
    "\n",
    "print(f\"\\nSPLIT SUMMARY:\")\n",
    "print(f\"Phase1 (D1 only):     {len(df_phase1)} files\")\n",
    "print(f\"Phase2 (D1+D2+D3):    {len(df_phase2)} files\")\n",
    "print(f\"Val (D1 only):        {len(df_d1_val)} files\")\n",
    "print(f\"Test (D1+D2+D3):      {len(df_test)} files\")\n",
    "print(f\"Total:                {len(df_phase1) + len(df_phase2) + len(df_d1_val) + len(df_test)} files\")\n",
    "\n",
    "print(f\"\\nTest distribution:\\n{df_test['emotion'].value_counts()}\")\n",
    "\n",
    "# ENSURE AUDIO FILES ARE VALID 16kHz\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 7: RESAMPLE & VALIDATE ALL AUDIO TO 16kHz\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "def ensure_16k_wav(src_path, dst_path):\n",
    "    \"\"\"\n",
    "    Read audio, convert to mono 16kHz wav, save to dst_path\n",
    "    NO torchaudio.load -> NO torchcodec\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1) Read audio\n",
    "        audio, sr = sf.read(src_path, dtype=\"float32\")\n",
    "\n",
    "        # 2) Mono\n",
    "        if audio.ndim > 1:\n",
    "            audio = audio.mean(axis=1)\n",
    "\n",
    "        # 3) Resample if needed\n",
    "        if sr != 16000:\n",
    "            audio = taF.resample(\n",
    "                torch.from_numpy(audio), sr, 16000\n",
    "            ).numpy()\n",
    "            sr = 16000\n",
    "\n",
    "        # 4) Save wav\n",
    "        sf.write(dst_path, audio, sr)\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error resampling {src_path}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b98ce453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 8: COPY FILES TO OUTPUT DIRECTORY\n",
      "============================================================\n",
      "\n",
      "Copying Phase1 (train)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3694/3694 [00:28<00:00, 131.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase1 (train): 3694 success, 0 failed\n",
      "\n",
      "Copying Phase2 (train)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3772/3772 [00:16<00:00, 227.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase2 (train): 3772 success, 0 failed\n",
      "\n",
      "Copying Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 792/792 [00:09<00:00, 87.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 792 success, 0 failed\n",
      "\n",
      "Copying Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 944/944 [00:04<00:00, 204.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 944 success, 0 failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "944"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 8: COPY FILES TO OUTPUT DIRECTORY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def copy_dataset_split(df, output_base, split_name):\n",
    "    \"\"\"Copy files from dataframe to organized folder structure\"\"\"\n",
    "    print(f\"\\nCopying {split_name}...\")\n",
    "\n",
    "    # Tạo folder emotion\n",
    "    for emotion in EMOTION_CLASSES:\n",
    "        os.makedirs(os.path.join(output_base, emotion), exist_ok=True)\n",
    "\n",
    "    # Counter riêng cho từng emotion\n",
    "    emotion_counters = {emotion: 0 for emotion in EMOTION_CLASSES}\n",
    "\n",
    "    success_count = 0\n",
    "    fail_count = 0\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        src = row[\"audio_path\"]\n",
    "        emotion = row[\"emotion\"]\n",
    "\n",
    "        emotion_counters[emotion] += 1\n",
    "        file_num = emotion_counters[emotion]\n",
    "\n",
    "        # Tên file: 1.wav, 2.wav, ...\n",
    "        filename = f\"{file_num}.wav\"\n",
    "        dst = os.path.join(output_base, emotion, filename)\n",
    "\n",
    "        if ensure_16k_wav(src, dst):\n",
    "            success_count += 1\n",
    "        else:\n",
    "            fail_count += 1\n",
    "\n",
    "    print(f\"{split_name}: {success_count} success, {fail_count} failed\")\n",
    "    return success_count\n",
    "\n",
    "\n",
    "# Create output structure\n",
    "for phase_dir in [TRAIN_PHASE1, TRAIN_PHASE2, VAL_DIR, TEST_DIR]:\n",
    "    os.makedirs(phase_dir, exist_ok=True)\n",
    "\n",
    "# Copy each split\n",
    "copy_dataset_split(df_phase1, TRAIN_PHASE1, \"Phase1 (train)\")\n",
    "copy_dataset_split(df_phase2, TRAIN_PHASE2, \"Phase2 (train)\")\n",
    "copy_dataset_split(df_d1_val, VAL_DIR, \"Validation\")\n",
    "copy_dataset_split(df_test, TEST_DIR, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4627985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 9: VERIFY OUTPUT STRUCTURE\n",
      "============================================================\n",
      "\n",
      "Phase1:\n",
      "  neutral: 855 files\n",
      "  happy: 1060 files\n",
      "  sad: 749 files\n",
      "  angry: 1030 files\n",
      "  TOTAL: 3694 files\n",
      "\n",
      "Phase2:\n",
      "  neutral: 877 files\n",
      "  happy: 1063 files\n",
      "  sad: 783 files\n",
      "  angry: 1049 files\n",
      "  TOTAL: 3772 files\n",
      "\n",
      "Validation:\n",
      "  neutral: 184 files\n",
      "  happy: 226 files\n",
      "  sad: 162 files\n",
      "  angry: 220 files\n",
      "  TOTAL: 792 files\n",
      "\n",
      "Test:\n",
      "  neutral: 220 files\n",
      "  happy: 266 files\n",
      "  sad: 196 files\n",
      "  angry: 262 files\n",
      "  TOTAL: 944 files\n",
      "\n",
      "============================================================\n",
      "STEP 10: SUMMARY STATISTICS\n",
      "============================================================\n",
      "\n",
      "Phase1:\n",
      "  Total files: 3694\n",
      "  Emotion distribution:\n",
      "    neutral: 855 (23.1%)\n",
      "    happy: 1060 (28.7%)\n",
      "    sad: 749 (20.3%)\n",
      "    angry: 1030 (27.9%)\n",
      "  Duration stats:\n",
      "    Min: 1.00s\n",
      "    Max: 12.86s\n",
      "    Mean: 2.16s\n",
      "\n",
      "Phase2:\n",
      "  Total files: 3772\n",
      "  Emotion distribution:\n",
      "    neutral: 877 (23.3%)\n",
      "    happy: 1063 (28.2%)\n",
      "    sad: 783 (20.8%)\n",
      "    angry: 1049 (27.8%)\n",
      "  Duration stats:\n",
      "    Min: 0.58s\n",
      "    Max: 15.00s\n",
      "    Mean: 2.47s\n",
      "\n",
      "Val:\n",
      "  Total files: 792\n",
      "  Emotion distribution:\n",
      "    neutral: 184 (23.2%)\n",
      "    happy: 226 (28.5%)\n",
      "    sad: 162 (20.5%)\n",
      "    angry: 220 (27.8%)\n",
      "  Duration stats:\n",
      "    Min: 1.00s\n",
      "    Max: 13.50s\n",
      "    Mean: 2.16s\n",
      "\n",
      "Test:\n",
      "  Total files: 944\n",
      "  Emotion distribution:\n",
      "    neutral: 220 (23.3%)\n",
      "    happy: 266 (28.2%)\n",
      "    sad: 196 (20.8%)\n",
      "    angry: 262 (27.8%)\n",
      "  Duration stats:\n",
      "    Min: 0.58s\n",
      "    Max: 15.00s\n",
      "    Mean: 2.44s\n",
      "\n",
      "============================================================\n",
      "✓ DATA MERGING COMPLETE\n",
      "============================================================\n",
      "\n",
      "Output directory structure created at: data/\n",
      "Ready for training!\n",
      "\n",
      "Metadata saved to data/metadata.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ============================================================\n",
    "# 9) VERIFY OUTPUT STRUCTURE\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 9: VERIFY OUTPUT STRUCTURE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def verify_split(split_path, split_name):\n",
    "    \"\"\"Count files in each emotion folder\"\"\"\n",
    "    print(f\"\\n{split_name}:\")\n",
    "    total = 0\n",
    "    for emotion in EMOTION_CLASSES:\n",
    "        emotion_dir = f\"{split_path}/{emotion}\"\n",
    "        if os.path.exists(emotion_dir):\n",
    "            count = len([f for f in os.listdir(emotion_dir) if f.endswith('.wav')])\n",
    "            total += count\n",
    "            print(f\"  {emotion}: {count} files\")\n",
    "    print(f\"  TOTAL: {total} files\")\n",
    "    return total\n",
    "\n",
    "verify_split(TRAIN_PHASE1, \"Phase1\")\n",
    "verify_split(TRAIN_PHASE2, \"Phase2\")\n",
    "verify_split(VAL_DIR, \"Validation\")\n",
    "verify_split(TEST_DIR, \"Test\")\n",
    "\n",
    "# ============================================================\n",
    "# 10) SUMMARY STATISTICS\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 10: SUMMARY STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "summary_data = {\n",
    "    'Phase1': (df_phase1, TRAIN_PHASE1),\n",
    "    'Phase2': (df_phase2, TRAIN_PHASE2),\n",
    "    'Val': (df_d1_val, VAL_DIR),\n",
    "    'Test': (df_test, TEST_DIR)\n",
    "}\n",
    "\n",
    "for split_name, (df_split, path) in summary_data.items():\n",
    "    print(f\"\\n{split_name}:\")\n",
    "    print(f\"  Total files: {len(df_split)}\")\n",
    "    print(f\"  Emotion distribution:\")\n",
    "    for emotion in EMOTION_CLASSES:\n",
    "        count = len(df_split[df_split['emotion'] == emotion])\n",
    "        pct = 100 * count / len(df_split) if len(df_split) > 0 else 0\n",
    "        print(f\"    {emotion}: {count} ({pct:.1f}%)\")\n",
    "    print(f\"  Duration stats:\")\n",
    "    print(f\"    Min: {df_split['duration'].min():.2f}s\")\n",
    "    print(f\"    Max: {df_split['duration'].max():.2f}s\")\n",
    "    print(f\"    Mean: {df_split['duration'].mean():.2f}s\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ DATA MERGING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nOutput directory structure created at: {OUTPUT_DIR}/\")\n",
    "print(\"Ready for training!\")\n",
    "\n",
    "# Optional: Save metadata\n",
    "metadata = {\n",
    "    'config': CONFIG,\n",
    "    'split_stats': {\n",
    "        'phase1': len(df_phase1),\n",
    "        'phase2': len(df_phase2),\n",
    "        'val': len(df_d1_val),\n",
    "        'test': len(df_test),\n",
    "    },\n",
    "    'emotion_classes': EMOTION_CLASSES\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(f\"{OUTPUT_DIR}/metadata.json\", 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(f\"\\nMetadata saved to {OUTPUT_DIR}/metadata.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
